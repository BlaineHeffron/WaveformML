{
  "run_config": {
    "exp_name": "sparseconvnet",
    "imports": ["src.engineering.LitPSD"],
    "run_class": "LitPSD"
  },
  "system_config":{
    "_comment": "set half_precision to true to utilize 16 bit training mode.",
    "_comment2": "set model_base_path to write model output to a directory of your choosing. Defaults to ./model",
    "model_name": "Positron_OrthoPositronium",
    "model_base_path": "./model",
    "n_type":2,
    "type_names": ["Positron","OrthoPositronium"],
    "n_samples": 150,
    "gpu_enabled": true,
    "half_precision": false
  },
  "net_config":{
    "_comment": "convolution args: dimension, nIn, nOut, filter_size, filter_stride, bias, groups=1",
    "criterion_class": "CrossEntropyLoss",
    "criterion_params": [],
    "imports": ["torch.nn","sparseconvnet","src.models.SCNet"],
    "net_class": "SCNet.SCNet",
    "sequence_class": "sparseconvnet.Sequential",
    "net_type": "2DConvolution",
    "validate_algorithm": false,
    "algorithm": [
      "sparseconvnet.Convolution", [
        2,
        300,
        37,
        1,
        1,
        false
      ],
      "sparseconvnet.Convolution", [
        2,
        37,
        37,
        3,
        1,
        false
      ],
      "sparseconvnet.Convolution", [
        2,
        37,
        18,
        3,
        2,
        false
      ],
      "sparseconvnet.SparseToDense", [2,18],
      "nn.Flatten", [],
      "nn.Linear", [
        270,
        135
      ],
      "nn.Linear", [
        135,
        32
      ],
      "nn.Linear", [
        32,
        2
      ]
    ]
  },
  "optimize_config":{
    "imports": ["torch.optim","torch.optim.lr_scheduler"],
    "total_epoch":30,
    "validation_freq":1,
    "lr": 1e-3,
    "optimizer_class": "optim.SGD",
    "optimizer_params": {
      "momentum": 0.9,
      "weight_decay": 0, "dampening": 0, "nesterov": true },
    "scheduler_class": "lr_scheduler.ExponentialLR",
    "scheduler_params": {
      "gamma": 0.9
    }
  },
  "dataset_config": {
    "_comment": "n_train and n_test correspond to the number trained per type",
    "_comment2": "dataset_class is set to the classname of the Dataset class being used",
    "_comment3": "cache_size is number of files to hold in memory",
    "_comment4": "a good starting point for num_workers is the number of cpus of the system",
    "_comment5": "chunk_size configures the number of rows of the hdf5 file accessed during iteration.",
    "_comment6": "set train_config, val_config, or test_config to the path to a dataset config to use that instead of paths to directories",
    "base_path": "/path/to/datafolder",
    "paths": ["Positron","OrthoPositronium"],
    "data_prep": "shuffle",
    "chunk_size": 1024,
    "shuffled_filesize": 16384,
    "imports": ["src.datasets.PulseDataset"],
    "dataset_class": "PulseDataset2D",
    "dataset_params": {
      "data_cache_size": 1
    },
    "dataloader_params": {
      "pin_memory": true,
      "num_workers": 4
    },
    "n_train": 1000000,
    "n_test": 1000000,
    "n_validate": 20000000
  },
  "optuna_config": {
    "_comment": "set the path to the parameters you would like to optimize",
    "hyperparameters": {
      "/optimize_config/optimizer_params/lr": [1e-7,1e-1],
      "/optimize_config/optimizer_params/momentum": [0.0, 1.0]
    },
    "optimize_args": {
      "n_trials": 100,
      "timeout": 600
    }
  }
}
